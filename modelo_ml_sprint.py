# -*- coding: utf-8 -*-
"""Modelo ML Sprint.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13J43IlkTN1Vetd_AQjP40-voV3GMR-3E
"""

import numpy as np
import pandas as pd

np.random.seed(42)
n = 4400000

# Base inicial com dados demogrÃ¡ficos e financeiros
df3 = pd.DataFrame({
    'Idade': np.random.randint(18, 70, n),
    'Renda': np.random.normal(12000, 4000, n).clip(2000, 30000),
    'TempoDeRelacao': np.random.randint(1, 121, n),
    'TicketMedioInvestido': np.random.uniform(10000, 2_000_000, n),
    'QtdProdutosNaCarteira': np.random.randint(1, 20, n),
    'PerfilRisco': np.random.choice([0, 1, 2], n, p=[0.3, 0.5, 0.2]),
    'Pais': np.random.choice(['Brasil', 'EUA', 'Alemanha'], n, p=[0.7, 0.2, 0.1]),
    'TaxaJuros': np.random.choice([13.75, 5.0, 2.0], n, p=[0.7, 0.2, 0.1])
})

# HistÃ³rico de investimento ESG influencia outras variÃ¡veis
df3['HistoricoInvestimentoESG'] = np.random.binomial(1, 0.3, n)

# Engajamento e conhecimento dependem do histÃ³rico
df3['EngajamentoESG'] = np.where(df3['HistoricoInvestimentoESG'] == 1,
                                 np.random.randint(8, 15, n),
                                 np.random.randint(0, 8, n))
df3['ConhecimentoESG'] = np.where(df3['HistoricoInvestimentoESG'] == 1,
                                  np.random.randint(3, 6, n),
                                  np.random.randint(1, 4, n))
df3['PreocupacaoAmbiental'] = np.clip(df3['ConhecimentoESG'] + np.random.randint(-1, 2, n), 1, 5)

# Comportamento online ESG depende do histÃ³rico
df3['AcessouPagESG'] = np.where(df3['HistoricoInvestimentoESG'] == 1,
                                np.random.binomial(1, 0.7, n),
                                np.random.binomial(1, 0.3, n))
df3['LeuArtigoESG'] = np.where(df3['HistoricoInvestimentoESG'] == 1,
                               np.random.binomial(1, 0.6, n),
                               np.random.binomial(1, 0.2, n))
df3['ParticipouWebinarESG'] = np.where(df3['HistoricoInvestimentoESG'] == 1,
                                       np.random.binomial(1, 0.4, n),
                                       np.random.binomial(1, 0.1, n))
df3['AssessorESGAtivo'] = np.where(df3['HistoricoInvestimentoESG'] == 1,
                                   np.random.binomial(1, 0.6, n),
                                   np.random.binomial(1, 0.2, n))

# NPS depende do engajamento
df3['NPS_ESG'] = np.clip((df3['EngajamentoESG'] / 1.5).astype(int) + np.random.randint(-1, 2, n), 0, 10)

# Valor alocado ESG somente para quem tem histÃ³rico
df3['ValorAlocadoESG'] = df3['HistoricoInvestimentoESG'] * np.random.uniform(5000, 100000, n)

# GeraÃ§Ã£o da variÃ¡vel target com dependÃªncia realista
proba_esg = (
    0.25 * df3['HistoricoInvestimentoESG'] +
    0.2 * df3['ParticipouWebinarESG'] +
    0.15 * df3['LeuArtigoESG'] +
    0.1 * df3['AcessouPagESG'] +
    0.1 * (df3['NPS_ESG'] >= 8).astype(int) +
    0.1 * (df3['EngajamentoESG'] >= 10).astype(int) +
    0.1 * (df3['ConhecimentoESG'] >= 4).astype(int) +
    0.2 * df3['AssessorESGAtivo']
)

df3['ESG_Label'] = np.random.binomial(1, np.clip(proba_esg, 0, 1))
df3.head(10)

df3.to_csv("base_clientes_xpertesg.csv", index=False)

!pip install xgboost --quiet

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
from sklearn.calibration import CalibratedClassifierCV
from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier

# âš ï¸ Use aqui o cÃ³digo anterior que gera o df3 com comportamento realista

# 2. Feature engineering
df3['score_interesse'] = df3['ConhecimentoESG'] * df3['EngajamentoESG']
df3['relacao_valor'] = df3['ValorAlocadoESG'] / (df3['TicketMedioInvestido'] + 1)

# 3. SeparaÃ§Ã£o dos dados
X = df3.drop(columns=['ESG_Label'])
y = df3['ESG_Label']
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# 4. PrÃ©-processamento
num_feats = [col for col in X.columns if X[col].dtype in ['float64', 'int64'] and col not in ['PerfilRisco']]
cat_feats = ['PerfilRisco', 'Pais', 'HistoricoInvestimentoESG', 'AcessouPagESG',
             'LeuArtigoESG', 'ParticipouWebinarESG', 'AssessorESGAtivo']

num_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])
cat_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
])
preprocessor = ColumnTransformer([
    ('num', num_pipeline, num_feats),
    ('cat', cat_pipeline, cat_feats)
])

X_train_transf = preprocessor.fit_transform(X_train)
X_test_transf = preprocessor.transform(X_test)

# 5. Etapa 1: XGBoost calibrado
xgb = XGBClassifier(
    scale_pos_weight=2,
    use_label_encoder=False,
    eval_metric='logloss',
    max_depth=4,
    learning_rate=0.1,
    n_estimators=100,
    subsample=0.8,
    colsample_bytree=0.8,
    reg_alpha=1,
    reg_lambda=1,
    random_state=42
)
xgb_calibrado = CalibratedClassifierCV(xgb, method='sigmoid', cv=3)
xgb_calibrado.fit(X_train_transf, y_train)
y_scores = xgb_calibrado.predict_proba(X_test_transf)[:, 1]

# --- Threshold escolhido ---
threshold = 0.46
usar_random_forest = False  # ou True se quiser RF como refinador

# --- Etapa 1: SeleÃ§Ã£o preliminar
y_pred_xgb = (y_scores >= threshold).astype(int)
X_test_refinar = X_test_transf[y_pred_xgb == 1]
y_test_refinar = y_test[y_pred_xgb == 1]

# --- Etapa 2: Refinador
if usar_random_forest:
    refiner = RandomForestClassifier(n_estimators=100, max_depth=4, class_weight='balanced', random_state=42)
else:
    refiner = LogisticRegression(max_iter=500, class_weight='balanced', C=1.0)

refiner.fit(X_train_transf, y_train)
y_pred_refinados = refiner.predict(X_test_refinar)

# --- PrediÃ§Ã£o final
y_pred_final = np.zeros_like(y_pred_xgb)
y_pred_final[y_pred_xgb == 1] = y_pred_refinados

# --- AvaliaÃ§Ã£o final
print(f"\nðŸŽ¯ AvaliaÃ§Ã£o final com 2 etapas (threshold={threshold}, modelo 2: {'RF' if usar_random_forest else 'LogReg'}):")
print(classification_report(y_test, y_pred_final, target_names=["NÃ£o ESG", "ESG"]))

cm = confusion_matrix(y_test, y_pred_final)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["NÃ£o ESG", "ESG"])
disp.plot(cmap='Blues', values_format='d')

